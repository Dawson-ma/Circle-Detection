{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R16RoXSz9P-o"
      },
      "source": [
        "# Circle Detection - Test\n",
        "Given the picture of a noisy circle, determine the of the center **(x, y)** and the radius **r** of the circle.\n",
        "\n",
        "Input:\n",
        "- ResNet18  \n",
        "  3-dimmension grayscale image\n",
        "- Self-defined CNN  \n",
        "  1-dimmension grayscale image\n",
        "\n",
        "Output:  \n",
        "- x: row of the circle center  \n",
        "- y: column of the circle center  \n",
        "- r: radius of the circle\n",
        "\n",
        "**Please specify the image and model variables in the Part 0. Finally, run the entire python code.**\n",
        "\n",
        "If model parameter file download is failed, please download the model parameter file (ex. model_resnet18.pt) from the [github](https://github.com/Dawson-ma/Circle-Detection) and upload to the colab.\n",
        "(Colab left bar>files>upload to session storage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz0MSU8BBZAx"
      },
      "source": [
        "## Part 0: Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKgFJ0e2BtvI"
      },
      "source": [
        "Sample and model variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jVrMH4z--IDa"
      },
      "outputs": [],
      "source": [
        "num_samples = 2000\n",
        "exist_dataset_path = None # If already have a dataset, please specify the path\n",
        "model_arch = 'Resnet18' # Resnet18 or CNN\n",
        "model_path = 'model_resnet18.pt' # 'model_resnet18.pt' or 'model_CNN.pt'\n",
        "iou_thres = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "145E-LZW-3yq"
      },
      "outputs": [],
      "source": [
        "# Fixed variables, please make sure to be same as training if modification is necessary\n",
        "noise_level = 0.5\n",
        "img_size = 100\n",
        "min_radius = img_size // 10\n",
        "max_radius = img_size // 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekvIKoBZB0I4"
      },
      "source": [
        "## Part I: Packages Preparation and Helper Function Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEtFy1hMB5RZ"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MxH0Z9MA9qe_"
      },
      "outputs": [],
      "source": [
        "# Package for mounting google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Package for loading data\n",
        "import json\n",
        "\n",
        "# Packages for model training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# Packages for helper function\n",
        "from typing import NamedTuple, Optional, Tuple, Generator\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.draw import circle_perimeter_aa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYIr9cqf7eVe",
        "outputId": "9fabe701-18b7-42ed-a755-53f60b3d983a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10bdgE1cyzuE737n2vCWcdobHw5tFSd2K\n",
            "To: /content/model_resnet18.pt\n",
            "100% 45.4M/45.4M [00:00<00:00, 65.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 10bdgE1cyzuE737n2vCWcdobHw5tFSd2K --output model_resnet18.pt\n",
        "!gdown --id 1bTGwja1qBQQq7ZKvfpskVO9saaVKkj0x --output model_CNN.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7gp1UA0B90h"
      },
      "source": [
        "### Helper functions\n",
        "Functions for generating noisy circle examples\n",
        "- CircleParams: Circle parameters (row, col, radius)\n",
        "- draw_circle: Draw a circle in a numpy array according to given row, col, and radius\n",
        "- noisy_circle: Draw a circle in a numpy array, with normal noise.\n",
        "- show_circle: Plot the given image\n",
        "- generate_examples: Generator for noisy circle examples\n",
        "- iou: Calculate the intersection over union of two circles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YCVf3qfe95-K"
      },
      "outputs": [],
      "source": [
        "class CircleParams(NamedTuple):\n",
        "    row: int\n",
        "    col: int\n",
        "    radius: int\n",
        "\n",
        "\n",
        "def draw_circle(img: np.ndarray, row: int, col: int, radius: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Draw a circle in a numpy array, inplace.\n",
        "    The center of the circle is at (row, col) and the radius is given by radius.\n",
        "    The array is assumed to be square.\n",
        "    Any pixels outside the array are ignored.\n",
        "    Circle is white (1) on black (0) background, and is anti-aliased.\n",
        "    \"\"\"\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, radius)\n",
        "    valid = (rr >= 0) & (rr < img.shape[0]) & (cc >= 0) & (cc < img.shape[1])\n",
        "    img[rr[valid], cc[valid]] = val[valid]\n",
        "    return img\n",
        "\n",
        "\n",
        "def noisy_circle(\n",
        "    img_size: int, min_radius: float, max_radius: float, noise_level: float\n",
        ") -> Tuple[np.ndarray, CircleParams]:\n",
        "    \"\"\"\n",
        "    Draw a circle in a numpy array, with normal noise.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an empty image\n",
        "    img = np.zeros((img_size, img_size))\n",
        "\n",
        "    radius = np.random.randint(min_radius, max_radius)\n",
        "\n",
        "    # x,y coordinates of the center of the circle\n",
        "    row, col = np.random.randint(img_size, size=2)\n",
        "\n",
        "    # Draw the circle inplace\n",
        "    draw_circle(img, row, col, radius)\n",
        "\n",
        "    added_noise = np.random.normal(0.5, noise_level, img.shape)\n",
        "    img += added_noise\n",
        "\n",
        "    return img, CircleParams(row, col, radius)\n",
        "\n",
        "\n",
        "def show_circle(img: np.ndarray):\n",
        "    \"\"\"Plot the given image\"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(img, cmap=\"gray\")\n",
        "    ax.set_title(\"Circle\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_examples(\n",
        "    noise_level: float = 0.5,\n",
        "    img_size: int = 100,\n",
        "    min_radius: Optional[int] = None,\n",
        "    max_radius: Optional[int] = None,\n",
        "    dataset_path: str = \"ds\",\n",
        ") -> Generator[Tuple[np.ndarray, CircleParams], None, None]:\n",
        "    \"\"\"\n",
        "    Generate noise circle image examples\n",
        "    \"\"\"\n",
        "    if not min_radius:\n",
        "        min_radius = img_size // 10\n",
        "    if not max_radius:\n",
        "        max_radius = img_size // 2\n",
        "    assert max_radius > min_radius, \"max_radius must be greater than min_radius\"\n",
        "    assert img_size > max_radius, \"size should be greater than max_radius\"\n",
        "    assert noise_level >= 0, \"noise should be non-negative\"\n",
        "\n",
        "    params = (\n",
        "        f\"{noise_level=}, {img_size=}, {min_radius=}, {max_radius=}, {dataset_path=}\"\n",
        "    )\n",
        "    print(f\"Using parameters: {params}\")\n",
        "    while True:\n",
        "        img, params = noisy_circle(\n",
        "            img_size=img_size,\n",
        "            min_radius=min_radius,\n",
        "            max_radius=max_radius,\n",
        "            noise_level=noise_level,\n",
        "        )\n",
        "        yield img, params\n",
        "\n",
        "\n",
        "def iou(a: CircleParams, b: CircleParams) -> float:\n",
        "    \"\"\"Calculate the intersection over union of two circles\"\"\"\n",
        "    r1, r2 = a.radius, b.radius\n",
        "    d = np.linalg.norm(np.array([a.row, a.col]) - np.array([b.row, b.col]))\n",
        "    if d > r1 + r2:\n",
        "        return 0\n",
        "    if d <= abs(r1 - r2):\n",
        "        return 1\n",
        "    r1_sq, r2_sq = r1**2, r2**2\n",
        "    d1 = (r1_sq - r2_sq + d**2) / (2 * d)\n",
        "    d2 = d - d1\n",
        "    h1 = r1_sq * np.arccos(d1 / r1)\n",
        "    h2 = d1 * np.sqrt(r1_sq - d1**2)\n",
        "    h3 = r2_sq * np.arccos(d2 / r2)\n",
        "    h4 = d2 * np.sqrt(r2_sq - d2**2)\n",
        "    intersection = h1 + h2 + h3 + h4\n",
        "    union = np.pi * (r1_sq + r2_sq) - intersection\n",
        "    return intersection / union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN44GG9vCWJ1"
      },
      "source": [
        "## Part II: Data Processing\n",
        "- Generate dataset\n",
        "- Define custom dataset for noisy circle images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEcQyQ4gCbC4"
      },
      "source": [
        "#### Generate dataset\n",
        "Generate data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ol43Xs-A_n",
        "outputId": "42fe06c1-2aa8-4145-c5e8-c8865eedb6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using parameters: noise_level=0.5, img_size=100, min_radius=10, max_radius=50, dataset_path='ds'\n"
          ]
        }
      ],
      "source": [
        "if not exist_dataset_path:\n",
        "    # Build the data generator\n",
        "    exGenerator = generate_examples(\n",
        "        noise_level, img_size, min_radius, max_radius\n",
        "    )\n",
        "\n",
        "    # Generate data\n",
        "    data = {}\n",
        "    for i in range(num_samples):\n",
        "        img, params = next(exGenerator)\n",
        "        data[f\"circle_{i:05d}\"] = {\n",
        "            \"img\": img.tolist(),\n",
        "            \"row\": int(params.row),\n",
        "            \"col\": int(params.col),\n",
        "            \"radius\": int(params.radius),\n",
        "        }\n",
        "else:\n",
        "    # Load dataset if existed\n",
        "    with open(exist_dataset_path) as f:\n",
        "        data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHpbFWBMCM0L"
      },
      "source": [
        "#### Custom Dataset\n",
        "Define a dataset for circle images and *labels*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "E83fhy-uAJEx"
      },
      "outputs": [],
      "source": [
        "class CircleDataset(Dataset):\n",
        "    def __init__(self, data: list, transform: transforms, RGB: bool):\n",
        "        # Dataset data\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x, self.y = [], []\n",
        "\n",
        "        # Iterate over the data\n",
        "        for d in data:\n",
        "            img = torch.FloatTensor(d[\"img\"])\n",
        "\n",
        "            # Transform 1 channel to 3 channels if required\n",
        "            if RGB:\n",
        "                img = img.expand(3, len(d[\"img\"]), len(d[\"img\"]))\n",
        "\n",
        "            self.x.append(img)\n",
        "            self.y.append(torch.FloatTensor([d[\"row\"], d[\"col\"], d[\"radius\"]]))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x[idx]), self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ0WVGJvCkQ9"
      },
      "source": [
        "## Part III: Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdFhwNeUDi9-"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Xlqqa1gYDtUX"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, 5)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 256, 3)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(256, 256, 3)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 32, 1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 4, 1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(4)\n",
        "\n",
        "        self.fc = nn.Linear(4*10*10, 3)\n",
        "        self.act = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1 * 100 * 100\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 64 * 48 * 48\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 256 * 23 * 23\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 256 * 10 * 10\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # 32 * 10 * 10\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # 4 * 10 * 10\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(-1, C * H * W)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJSh1IXkCzeW"
      },
      "source": [
        "### Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Jo7w9B-J9Qec"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataset, iou_thres, device):\n",
        "    # Specify the device used to train the model\n",
        "    model.to(device)\n",
        "\n",
        "    # Loss criterion\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=128, shuffle=False, drop_last=False\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "\n",
        "    # Define variables\n",
        "    test_loss, test_iou, test_acc = 0.0, 0.0, 0.0\n",
        "\n",
        "    # Iterate over test data.\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(labels, outputs)\n",
        "\n",
        "        # statistics\n",
        "        test_loss += loss.item()\n",
        "        # Calculate accuracy and mean iou\n",
        "        labels = labels.cpu()\n",
        "        outputs = outputs.cpu()\n",
        "        for truth, pred in zip(labels, outputs):\n",
        "            sample_iou = iou(\n",
        "                CircleParams(truth[0], truth[1], truth[2]),\n",
        "                CircleParams(pred[0], pred[1], pred[2]),\n",
        "            )\n",
        "            test_acc += 1 if sample_iou >= iou_thres else 0\n",
        "            test_iou += sample_iou\n",
        "\n",
        "    print(f\"Test evaluation:\")\n",
        "    print(f\"iou threshold: {iou_thres}\")\n",
        "    print(\n",
        "        f\"loss: {test_loss:.4f} acc: {test_acc/len(dataset):.4f} iou: {test_iou/len(dataset)}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw12f0cEC-Tm"
      },
      "source": [
        "### Evaluation Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1guWVkaDC9Jj"
      },
      "source": [
        "Define data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fMKkSRvVAMI-"
      },
      "outputs": [],
      "source": [
        "if model_arch == 'Resnet18':\n",
        "    data_transforms = transforms.Compose(\n",
        "        [transforms.Normalize(mean=[0.456, 0.456, 0.456], std=[0.225, 0.225, 0.225])]\n",
        "    )\n",
        "else:\n",
        "    data_transforms = transforms.Compose(\n",
        "        [transforms.Normalize(mean=[0.456], std=[0.225])]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ0qEkbFDEA-"
      },
      "source": [
        "Construct dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9fNozH6yAOtC"
      },
      "outputs": [],
      "source": [
        "# Extract data val and labels\n",
        "data = [val for _, val in data.items()]\n",
        "\n",
        "# Construct test dataset\n",
        "dataset = CircleDataset(data, data_transforms, RGB=True if model_arch=='Resnet18' else False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO-tdabKDHas"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5YwwGr_m-HI3"
      },
      "outputs": [],
      "source": [
        "model = resnet18() if model_arch == 'Resnet18' else None\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 3),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Lrs3MkDNuV"
      },
      "source": [
        "Load the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8JI-9t75BoRf"
      },
      "outputs": [],
      "source": [
        "# Recognize the device\n",
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us7bhoxHBIOC",
        "outputId": "34feb612-d1d2-4438-ead2-b36951550875"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=16, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if device == \"cpu\":\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acA2nobBDRTo"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ItGKGtdBM6k",
        "outputId": "2bcdc3ad-33b9-42e1-87c9-e59bfd6ef81c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test evaluation:\n",
            "iou threshold: 0.95\n",
            "loss: 19.4413 acc: 0.9535 iou: 0.9880501627922058\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, dataset, iou_thres, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
