{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a5164Qu26IJ"
      },
      "source": [
        "# Circle Detection - Train\n",
        "Given the picture of a noisy circle, determine the of the center **(x, y)** and the radius **r** of the circle.\n",
        "\n",
        "Input:\n",
        "- ResNet18  \n",
        "  3-dimmension grayscale image\n",
        "- Self-defined CNN  \n",
        "  1-dimmension grayscale image\n",
        "\n",
        "Output:  \n",
        "- x: row of the circle center  \n",
        "- y: column of the circle center  \n",
        "- r: radius of the circle\n",
        "\n",
        "**Please specify the image and model variables in the Part 0, and run the entire python code.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdKj3DoxyXAi"
      },
      "source": [
        "## Part 0: Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjLrAj01H4B3"
      },
      "source": [
        "Sample variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HM-FHZmJ5jfb"
      },
      "outputs": [],
      "source": [
        "num_samples = 20000\n",
        "noise_level = 0.5\n",
        "img_size = 100\n",
        "min_radius = img_size // 10\n",
        "max_radius = img_size // 2\n",
        "dataset_path = None # Specify the path if the dataset needed to be save, ex. \"/content/drive/MyDrive/data.json\"\n",
        "exist_dataset_path = None # If already have a dataset, please specify the path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LZ2omnyHA0"
      },
      "source": [
        "Model hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B2oVtAiuyAy8"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"arch\": \"Resnet18\", # Resnet18/CNN\n",
        "    \"n_epochs\": 50,\n",
        "    \"train_batch_size\": 256,\n",
        "    \"val_batch_size\": 256,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optim_hparas\": {\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    \"lambda\": 0.996, # Learning rate scheduler decay lambda\n",
        "    \"iou_thres\": 0.95,\n",
        "    \"noise_level\": noise_level,\n",
        "    \"save_path\": None # ex. \"/content/drive/MyDrive/CircleDetection/Models\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp-D1jIHCYI-"
      },
      "source": [
        "## Part I: Packages Preparation and Helper Function Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p84dU22e3IQL"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "baTrMfuZ3FlN"
      },
      "outputs": [],
      "source": [
        "# Package for mounting google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Package for storing data\n",
        "import csv\n",
        "import json\n",
        "import codecs\n",
        "import time\n",
        "\n",
        "# Packages for model training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "# Packages for helper function\n",
        "from typing import NamedTuple, Optional, Tuple, Generator\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.draw import circle_perimeter_aa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41mkd0Lp28f4"
      },
      "source": [
        "### Helper functions\n",
        "Functions for generating noisy circle examples\n",
        "- CircleParams: Circle parameters (row, col, radius)\n",
        "- draw_circle: Draw a circle in a numpy array according to given row, col, and radius\n",
        "- noisy_circle: Draw a circle in a numpy array, with normal noise.\n",
        "- show_circle: Plot the given image\n",
        "- generate_examples: Generator for noisy circle examples\n",
        "- iou: Calculate the intersection over union of two circles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W9hvBbOw2-rW"
      },
      "outputs": [],
      "source": [
        "class CircleParams(NamedTuple):\n",
        "    row: int\n",
        "    col: int\n",
        "    radius: int\n",
        "\n",
        "\n",
        "def draw_circle(img: np.ndarray, row: int, col: int, radius: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Draw a circle in a numpy array, inplace.\n",
        "    The center of the circle is at (row, col) and the radius is given by radius.\n",
        "    The array is assumed to be square.\n",
        "    Any pixels outside the array are ignored.\n",
        "    Circle is white (1) on black (0) background, and is anti-aliased.\n",
        "    \"\"\"\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, radius)\n",
        "    valid = (rr >= 0) & (rr < img.shape[0]) & (cc >= 0) & (cc < img.shape[1])\n",
        "    img[rr[valid], cc[valid]] = val[valid]\n",
        "    return img\n",
        "\n",
        "\n",
        "def noisy_circle(\n",
        "    img_size: int, min_radius: float, max_radius: float, noise_level: float\n",
        ") -> Tuple[np.ndarray, CircleParams]:\n",
        "    \"\"\"\n",
        "    Draw a circle in a numpy array, with normal noise.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create an empty image\n",
        "    img = np.zeros((img_size, img_size))\n",
        "\n",
        "    radius = np.random.randint(min_radius, max_radius)\n",
        "\n",
        "    # x,y coordinates of the center of the circle\n",
        "    row, col = np.random.randint(img_size, size=2)\n",
        "\n",
        "    # Draw the circle inplace\n",
        "    draw_circle(img, row, col, radius)\n",
        "\n",
        "    added_noise = np.random.normal(0.5, noise_level, img.shape)\n",
        "    img += added_noise\n",
        "\n",
        "    return img, CircleParams(row, col, radius)\n",
        "\n",
        "\n",
        "def show_circle(img: np.ndarray):\n",
        "    \"\"\"Plot the given image\"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(img, cmap=\"gray\")\n",
        "    ax.set_title(\"Circle\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_examples(\n",
        "    noise_level: float = 0.5,\n",
        "    img_size: int = 100,\n",
        "    min_radius: Optional[int] = None,\n",
        "    max_radius: Optional[int] = None,\n",
        "    dataset_path: str = \"ds\",\n",
        ") -> Generator[Tuple[np.ndarray, CircleParams], None, None]:\n",
        "    \"\"\"\n",
        "    Generate noise circle image examples\n",
        "    \"\"\"\n",
        "    if not min_radius:\n",
        "        min_radius = img_size // 10\n",
        "    if not max_radius:\n",
        "        max_radius = img_size // 2\n",
        "    assert max_radius > min_radius, \"max_radius must be greater than min_radius\"\n",
        "    assert img_size > max_radius, \"size should be greater than max_radius\"\n",
        "    assert noise_level >= 0, \"noise should be non-negative\"\n",
        "\n",
        "    params = (\n",
        "        f\"{noise_level=}, {img_size=}, {min_radius=}, {max_radius=}, {dataset_path=}\"\n",
        "    )\n",
        "    print(f\"Using parameters: {params}\")\n",
        "    while True:\n",
        "        img, params = noisy_circle(\n",
        "            img_size=img_size,\n",
        "            min_radius=min_radius,\n",
        "            max_radius=max_radius,\n",
        "            noise_level=noise_level,\n",
        "        )\n",
        "        yield img, params\n",
        "\n",
        "\n",
        "def iou(a: CircleParams, b: CircleParams) -> float:\n",
        "    \"\"\"Calculate the intersection over union of two circles\"\"\"\n",
        "    r1, r2 = a.radius, b.radius\n",
        "    d = np.linalg.norm(np.array([a.row, a.col]) - np.array([b.row, b.col]))\n",
        "    if d > r1 + r2:\n",
        "        return 0\n",
        "    if d <= abs(r1 - r2):\n",
        "        return 1\n",
        "    r1_sq, r2_sq = r1**2, r2**2\n",
        "    d1 = (r1_sq - r2_sq + d**2) / (2 * d)\n",
        "    d2 = d - d1\n",
        "    h1 = r1_sq * np.arccos(d1 / r1)\n",
        "    h2 = d1 * np.sqrt(r1_sq - d1**2)\n",
        "    h3 = r2_sq * np.arccos(d2 / r2)\n",
        "    h4 = d2 * np.sqrt(r2_sq - d2**2)\n",
        "    intersection = h1 + h2 + h3 + h4\n",
        "    union = np.pi * (r1_sq + r2_sq) - intersection\n",
        "    return intersection / union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed05ATgq2u4V"
      },
      "source": [
        "## Part II: Data Processing\n",
        "- Generate dataset\n",
        "- Define custom dataset for noisy circle images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZjxBmx3LXf"
      },
      "source": [
        "#### Generate dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7O5T75yCQp-"
      },
      "source": [
        "Generate data for training and evaluating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9Xc6esBY3Lrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53481d08-8479-4e1b-faea-8df882a84eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using parameters: noise_level=0.5, img_size=100, min_radius=10, max_radius=50, dataset_path=None\n"
          ]
        }
      ],
      "source": [
        "if not exist_dataset_path:\n",
        "    # Build the data generator\n",
        "    exGenerator = generate_examples(\n",
        "        noise_level, img_size, min_radius, max_radius, dataset_path\n",
        "    )\n",
        "\n",
        "    # Generate data\n",
        "    data = {}\n",
        "    for i in range(num_samples):\n",
        "        img, params = next(exGenerator)\n",
        "        data[f\"circle_{i:05d}\"] = {\n",
        "            \"img\": img.tolist(),\n",
        "            \"row\": int(params.row),\n",
        "            \"col\": int(params.col),\n",
        "            \"radius\": int(params.radius),\n",
        "        }\n",
        "else:\n",
        "    # Load dataset if existed\n",
        "    with open(dataset_path) as f:\n",
        "        data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lr5UR-3ICHR"
      },
      "source": [
        "Save the dataset if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7QglmHqNHg7Y"
      },
      "outputs": [],
      "source": [
        "if dataset_path:\n",
        "    # Mount the google drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    # Save data as json file\n",
        "    json.dump(data, codecs.open(dataset_path, 'w', encoding='utf-8'), indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuTyNFyPfkYf"
      },
      "source": [
        "#### Custom Dataset\n",
        "Define a dataset for circle images and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wlV4AD94fjJu"
      },
      "outputs": [],
      "source": [
        "class CircleDataset(Dataset):\n",
        "    def __init__(self, data: list, transform: transforms, RGB: bool):\n",
        "        # Dataset data\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.x, self.y = [], []\n",
        "\n",
        "        # Iterate over the data\n",
        "        for d in data:\n",
        "            img = torch.FloatTensor(d[\"img\"])\n",
        "\n",
        "            # Transform 1 channel to 3 channels if required\n",
        "            img = img.expand(3 if RGB else 1, len(d[\"img\"]), len(d[\"img\"]))\n",
        "\n",
        "            self.x.append(img)\n",
        "            self.y.append(torch.FloatTensor([d[\"row\"], d[\"col\"], d[\"radius\"]]))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(self.x[idx]), self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS9pwpq0oE3_"
      },
      "source": [
        "## Part III: Machine Learning Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT1JG42A2hdO"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J6uByDlmEkCK"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, 5)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 256, 3)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(256, 256, 3)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 32, 1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(32, 4, 1)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(4)\n",
        "\n",
        "        self.fc = nn.Linear(4*10*10, 3)\n",
        "        self.act = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1 * 100 * 100\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 64 * 48 * 48\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 256 * 23 * 23\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.act(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # 256 * 10 * 10\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # 32 * 10 * 10\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        # 4 * 10 * 10\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(-1, C * H * W)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaV0ANIumSxq"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xLHOZ-ipmV-C"
      },
      "outputs": [],
      "source": [
        "def train(config, model, datasets):\n",
        "    # Starting time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU to train the model\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Loss criterion\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = getattr(torch.optim, config[\"optimizer\"])(\n",
        "        model.parameters(), **config[\"optim_hparas\"]\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lambda1 = lambda epoch: config[\"lambda\"] ** epoch\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "    # Dataloader\n",
        "    dataloaders = {\n",
        "        \"train\": torch.utils.data.DataLoader(\n",
        "            datasets[\"train\"],\n",
        "            batch_size=config[\"train_batch_size\"],\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "        ),\n",
        "        \"val\": torch.utils.data.DataLoader(\n",
        "            datasets[\"val\"],\n",
        "            batch_size=config[\"val_batch_size\"],\n",
        "            shuffle=True,\n",
        "            drop_last=True,\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    # Training\n",
        "    best_loss = 1000.0\n",
        "    loss_record = {\"train\": [], \"val\": []}\n",
        "    for epoch in range(config['n_epochs']):\n",
        "        print(f\"Epoch: {epoch+1}\")\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            # Set model mode based on training or evaluating\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            # Define running variables\n",
        "            total = 0\n",
        "            running_loss = 0.0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                total += inputs.size(0)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(labels, outputs)\n",
        "\n",
        "                    # Backward and optimize only if in training phase\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    scheduler.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            running_loss /= total\n",
        "\n",
        "            # Record loss\n",
        "            loss_record[phase].append(running_loss)\n",
        "\n",
        "            # Display the result\n",
        "            print(f\"{phase} loss: {running_loss:.4f}\")\n",
        "\n",
        "            # Model checkpoint\n",
        "            if config[\"save_path\"]:\n",
        "                if epoch % 5 == 0:\n",
        "                    # Save model checkpoint\n",
        "                    torch.save(\n",
        "                        model.state_dict(),\n",
        "                        f\"{config['save_path']}/model_{epoch:05d}.pt\",\n",
        "                    )\n",
        "                    # Save model loss record\n",
        "                    with open(f\"{config['save_path']}/{config['arch']}_noise{config['noise_level']*10}_loss_record.csv\", \"w\") as f:\n",
        "                        write = csv.writer(f)\n",
        "                        write.writerow(config)\n",
        "                        write.writerows([loss_record[\"train\"]])\n",
        "                        write.writerows([loss_record[\"val\"]])\n",
        "\n",
        "                # Save the best model\n",
        "                if phase == \"val\" and running_loss < best_loss:\n",
        "                    print(f\"Model saved with epoch {epoch} and loss {running_loss:.4f}\")\n",
        "                    best_loss = running_loss\n",
        "                    torch.save(\n",
        "                        model.state_dict(), f\"{config['save_path']}/best_model.pt\"\n",
        "                    )\n",
        "\n",
        "        print(f\"Time elapsed: {time.time()-start_time}\")\n",
        "        print()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL3nQU6ZyLa8"
      },
      "source": [
        "#### Training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGW7hRVSPDZo"
      },
      "source": [
        "Define data transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zMHfVRUNg01D"
      },
      "outputs": [],
      "source": [
        "if config['arch'] == 'Resnet18':\n",
        "    data_transforms = transforms.Compose(\n",
        "        [transforms.Normalize(mean=[0.456, 0.456, 0.456], std=[0.225, 0.225, 0.225])]\n",
        "    )\n",
        "else:\n",
        "    data_transforms = transforms.Compose(\n",
        "        [transforms.Normalize(mean=[0.456], std=[0.225])]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8jJ1ZSKPHz-"
      },
      "source": [
        "Construct dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bA6Fz-OtyKVJ"
      },
      "outputs": [],
      "source": [
        "# Extract data val and labels\n",
        "data = [val for _, val in data.items()]\n",
        "\n",
        "# Construct training, validation, and test dataset with proportion 7: 2: 1\n",
        "RGB = True if config['arch'] == 'Resnet18' else False\n",
        "dataset = {}\n",
        "dataset[\"train\"] = CircleDataset(\n",
        "    data[: int(len(data) * 0.7)], data_transforms, RGB\n",
        ")\n",
        "dataset[\"val\"] = CircleDataset(\n",
        "    data[int(len(data) * 0.7) : int(len(data) * 0.9)], data_transforms, RGB\n",
        ")\n",
        "dataset[\"test\"] = CircleDataset(data[int(len(data) * 0.9) :], data_transforms, RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bCSWvyAPzYk"
      },
      "source": [
        "Define model and modify the output layer to predict (x, y, radius)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LeowIgK-4mP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32896b25-3462-486b-f0a4-422013f19102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 90.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = resnet18(weights=ResNet18_Weights.DEFAULT) if config['arch'] == 'Resnet18' else CNN()\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(model.fc.in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 3),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6-SG4GtP_2l"
      },
      "source": [
        "Training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vjoEtVzfeuxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46a3bca-b201-43e2-eb91-6d7d60219b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "train loss: 3.5176\n",
            "val loss: 1.3625\n",
            "Time elapsed: 38.68523621559143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = train(config, model, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9W8jebUQFNQ"
      },
      "source": [
        "## Part IX: Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhI9H-o29bk"
      },
      "source": [
        "Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pPaIN42A49x1"
      },
      "outputs": [],
      "source": [
        "def evaluate(config, model, datasets):\n",
        "    # Use GPU to train the model\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Loss criterion\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Dataloader\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset[\"test\"], batch_size=128, shuffle=False, drop_last=False\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "\n",
        "    # Define variables\n",
        "    test_loss, test_iou, test_acc = 0.0, 0.0, 0.0\n",
        "\n",
        "    # Iterate over test data.\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(labels, outputs)\n",
        "\n",
        "        # statistics\n",
        "        test_loss += loss.item()\n",
        "        # Calculate accuracy and mean iou\n",
        "        labels = labels.cpu()\n",
        "        outputs = outputs.cpu()\n",
        "        for truth, pred in zip(labels, outputs):\n",
        "            sample_iou = iou(\n",
        "                CircleParams(truth[0], truth[1], truth[2]),\n",
        "                CircleParams(pred[0], pred[1], pred[2]),\n",
        "            )\n",
        "            test_acc += 1 if sample_iou >= config[\"iou_thres\"] else 0\n",
        "            test_iou += sample_iou\n",
        "\n",
        "    print(f\"Test evaluation:\")\n",
        "    print(f\"iou threshold: {config['iou_thres']}\")\n",
        "    print(\n",
        "        f\"loss: {test_loss:.4f} acc: {test_acc/len(datasets['test']):.4f} iou: {test_iou/len(datasets['test'])}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE9lkxjAQaoX"
      },
      "source": [
        "Load the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-LOmt8HIQYnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a9b00a-712e-4b0b-d5b4-b49ad25dd18a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=16, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=16, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "if config['save_path']:\n",
        "    model.load_state_dict(torch.load(f\"{config['save_path']}/best_model.pt\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LUEidMbQe7P"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_DUvqE9Qr67Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47374970-9b53-4204-b8e2-9ffa2cb6fb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test evaluation:\n",
            "iou threshold: 0.95\n",
            "loss: 5651.1384 acc: 0.2905 iou: 0.7145925760269165\n"
          ]
        }
      ],
      "source": [
        "evaluate(config, model, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Oojsc-Hb8Rff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}